{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating files with label for leaderboard test\n",
    "\n",
    "In this kit, we will show how to use the trained model to generate labels and save the labels for uploading. We recommand you to read the 'LeaderboardDataGuide' to get familar with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu condition:  True\n"
     ]
    }
   ],
   "source": [
    "from util.preproc import balance_set,plot_confusion_matrix\n",
    "import torch\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt \n",
    "from braindecode.util import np_to_var, var_to_np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from braindecode.util import set_random_seeds\n",
    "import util.shallow_net\n",
    "from util.utilfunc import get_balanced_batches\n",
    "\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print('gpu condition: ', cuda)\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "\n",
    "SEED=42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "rng = RandomState(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These Objects are the same as in sleep and motor imagery kits.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestObject(object):\n",
    "    def __init__(self, X):\n",
    "        mean=np.mean(X,axis=1,keepdims=True)\n",
    "        std=np.std(X,axis=1,keepdims=True)\n",
    "        X=(X-mean)/(std)\n",
    "        #we scale it to 1000 as a better training scale of the shallow CNN\n",
    "        #according to the orignal work of the paper\n",
    "        self.X = X.astype(np.float32)*1e3\n",
    "class SleepObject(object):\n",
    "    def __init__(self, X):\n",
    "        mean=np.mean(X,axis=2,keepdims=True)\n",
    "        #here normalise across the window, when channel size is large enough\n",
    "        std=np.std(X,axis=2,keepdims=True)\n",
    "        X=(X-mean)/(std)\n",
    "        #we scale it to 1000 as a better training scale of the shallow CNN\n",
    "        #according to the orignal work of the paper\n",
    "        self.X = X.astype(np.float32)*1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_label=None\n",
    "MI_s1=None\n",
    "MI_s2=None\n",
    "MI_s3=None\n",
    "MI_s4=None\n",
    "MI_s5=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading test data has been explained in the DataGuide. Replace the 'savebase' part with your folder. After loading the test data, model trained with the training set can be loaded to do the prediction. 13094 trials for leaderboard sleep test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall test size\n",
      "(25748, 2, 3000)\n",
      "[[ 1.7581476e+03  4.1160596e+02  2.1550768e+02 -2.0283537e+02\n",
      "   1.1437063e+03  1.1959991e+03  1.2352188e+03  1.1829259e+03\n",
      "   6.2077747e+02 -2.0283537e+02 -8.5176384e+01 -2.9434790e+02\n",
      "  -9.8722858e+02 -2.1245986e+03 -1.9154271e+03 -1.3271322e+03\n",
      "  -1.8976215e+02  2.1895637e+03  3.5753252e+03  2.4641016e+03]\n",
      " [ 2.3038503e+02 -1.6435357e+00 -4.3669708e+02 -2.0466852e+02\n",
      "  -2.3367210e+02  4.4791180e+02  7.3794751e+02  9.5547424e+02\n",
      "   1.4050297e+03  2.0286064e+03  1.6080547e+03  7.8145282e+02\n",
      "   4.6241357e+02  7.8145282e+02  1.8687967e+02 -2.7717746e+02\n",
      "  -1.0602739e+03 -2.1624094e+03 -2.0318934e+03 -1.2052916e+03]]\n",
      "3000\n",
      "(25748,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 2, 2, 1, 1, 2, 2, 2, 0, 0, 1, 1, 5, 0, 2, 2, 0, 2, 0,\n",
       "       0, 5, 0, 0, 0, 1, 0, 0, 0, 0, 0, 5, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1,\n",
       "       5, 2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 0, 0, 2, 0, 0, 0, 2, 0, 1, 2, 0,\n",
       "       0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       2, 0, 0, 1, 1, 1, 2, 1, 2, 0, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savebase = 'D:\\\\leaderboardData\\\\LeaderboardSleep\\\\testing\\\\'\n",
    "\n",
    "X_test = []\n",
    "for subj in range(6, 18):\n",
    "    for session in range(1, 3):\n",
    "        with open(savebase + \"leaderboard_s{}r{}X.npy\".format(subj, session), 'rb') as f:\n",
    "            X_test.append(pickle.load(f))\n",
    "X_test = np.concatenate(X_test)\n",
    "\n",
    "print('overall test size')\n",
    "print(X_test.shape)\n",
    "test_set = SleepObject(X_test)\n",
    "print(test_set.X[1,:,:20])\n",
    "\n",
    "\n",
    "savebase0='D:\\\\sleep'\n",
    "\n",
    "set_random_seeds(seed=42, cuda=cuda)\n",
    "input_time_length = X_test.shape[2]\n",
    "print(input_time_length)\n",
    "in_chans=X_test.shape[1]\n",
    "model = util.shallow_net.EEGShallowClassifier(in_chans, 6, input_time_length, return_feature=False)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "checkpoint = torch.load(savebase0+'\\\\cnn_model_sleep.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "average_acc=[]\n",
    "average_loss=[]\n",
    "setname='testset'\n",
    "dataset=test_set\n",
    "\n",
    "#shuffle=False to make sure it's in the orignial order\n",
    "i_trials_in_batch = get_balanced_batches(len(dataset.X), rng, shuffle=False,\n",
    "                                    batch_size=30)\n",
    "outputs=None\n",
    "for i_trials in i_trials_in_batch:\n",
    "    # Have to add empty fourth dimension to X\n",
    "    batch_X = dataset.X[i_trials][:,:,:,None]\n",
    "    net_in = np_to_var(batch_X)\n",
    "    if cuda:\n",
    "        net_in = net_in.cuda()\n",
    "    toutputs = model(net_in)\n",
    "    if outputs is None:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=temp.detach().numpy()\n",
    "    else:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=np.concatenate((outputs,temp.detach().numpy()))\n",
    "predicted_labels = np.argmax((outputs), axis=1)\n",
    "print(predicted_labels.shape)\n",
    "sleep_label = predicted_labels\n",
    "predicted_labels[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**200 trials for leaderboard MI test data for each subject 1-5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 6\n",
      "(20, 63, 2000)\n",
      "run 7\n",
      "(40, 63, 2000)\n",
      "run 8\n",
      "(60, 63, 2000)\n",
      "run 9\n",
      "(80, 63, 2000)\n",
      "run 10\n",
      "(100, 63, 2000)\n",
      "run 11\n",
      "(120, 63, 2000)\n",
      "run 12\n",
      "(140, 63, 2000)\n",
      "run 13\n",
      "(160, 63, 2000)\n",
      "run 14\n",
      "(180, 63, 2000)\n",
      "run 15\n",
      "(200, 63, 2000)\n",
      "overall test size\n",
      "(200, 22, 2000)\n",
      "True\n",
      "2000\n",
      "(200,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 2, 0, 0, 2, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 2, 0, 1, 0, 0, 1, 0, 0, 0, 2, 1, 0, 1, 2,\n",
       "       1, 0, 1, 2, 1, 0, 1, 1, 0, 2, 0, 1, 0, 0, 1, 0, 0, 2, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 2, 1, 1, 1, 2, 0, 1, 0,\n",
       "       2, 0, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 2, 2, 2,\n",
       "       1, 1, 2, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 2], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pilotname='S1'\n",
    "savebase0='D:\\\\leaderboardData\\\\leaderboardMI\\\\'\n",
    "savebase = savebase0+pilotname+'\\\\'+'testing\\\\'\n",
    "\n",
    "# read crop data\n",
    "ch_names =['Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', \n",
    "           'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', \n",
    "           'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'C4', 'T8',\n",
    "           'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'AF7', 'AF3', \n",
    "           'AFz', 'F1', 'F5', 'FT7', 'FC3', 'FCz', 'C1', 'C5', \n",
    "           'TP7', 'CP3', 'P1', 'P5', 'PO7', 'PO3', 'POz', 'PO4', \n",
    "           'PO8', 'P6', 'P2', 'CPz', 'CP4', 'TP8', 'C6', 'C2',\n",
    "           'FC4', 'FT8', 'F6', 'F2', 'AF4', 'AF8']\n",
    "#here we used the ones arround motor cortex\n",
    "good_indices=[7,8,11,12,13,14,19,22,23,24,28]+[39,40,43,44,45,51,52,53,54,57,58]\n",
    "good_indices[:] = [x - 1 for x in good_indices]\n",
    "\n",
    "for i in range(5,15):\n",
    "    with open (savebase+\"race\"+str(i+1)+\"_padsData.npy\", 'rb') as fp:\n",
    "        Xt = pickle.load(fp)\n",
    "    if i==5:\n",
    "        X0 = Xt\n",
    "    else:\n",
    "        X0 = np.concatenate((X0,Xt))\n",
    "    print('run',i+1)\n",
    "    print(X0.shape)   \n",
    "    \n",
    "X_test = X0[:,good_indices,:]\n",
    "\n",
    "print('overall test size')\n",
    "print(X_test.shape)\n",
    "test_set = TestObject(X_test)\n",
    "\n",
    "print(cuda)\n",
    "set_random_seeds(seed=42, cuda=cuda)\n",
    "input_time_length = X_test.shape[2]\n",
    "print(input_time_length)\n",
    "in_chans=X_test.shape[1]\n",
    "labelsize=3\n",
    "model = util.shallow_net.EEGShallowClassifier(in_chans, labelsize, input_time_length, return_feature=False)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "checkpoint = torch.load('D:\\\\motor_imagery\\\\MImodelinLeaderboard\\\\'+'cnn_model_MI_'+pilotname+'.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "average_acc=[]\n",
    "average_loss=[]\n",
    "setname='testset'\n",
    "dataset=test_set\n",
    "\n",
    "i_trials_in_batch = get_balanced_batches(len(dataset.X), rng, shuffle=False,\n",
    "                                    batch_size=30)\n",
    "outputs=None\n",
    "for i_trials in i_trials_in_batch:\n",
    "    # Have to add empty fourth dimension to X\n",
    "#             print(i_trials)\n",
    "    batch_X = dataset.X[i_trials][:,:,:,None]\n",
    "#     batch_y = dataset.y[i_trials]\n",
    "    net_in = np_to_var(batch_X)\n",
    "    if cuda:\n",
    "        net_in = net_in.cuda()\n",
    "    toutputs = model(net_in)\n",
    "    if outputs is None:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=temp.detach().numpy()\n",
    "    else:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=np.concatenate((outputs,temp.detach().numpy()))\n",
    "predicted_labels = np.argmax((outputs), axis=1)\n",
    "print(predicted_labels.shape)\n",
    "MI_s1 = predicted_labels\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 6\n",
      "(20, 63, 2000)\n",
      "run 7\n",
      "(40, 63, 2000)\n",
      "run 8\n",
      "(60, 63, 2000)\n",
      "run 9\n",
      "(80, 63, 2000)\n",
      "run 10\n",
      "(100, 63, 2000)\n",
      "run 11\n",
      "(120, 63, 2000)\n",
      "run 12\n",
      "(140, 63, 2000)\n",
      "run 13\n",
      "(160, 63, 2000)\n",
      "run 14\n",
      "(180, 63, 2000)\n",
      "run 15\n",
      "(200, 63, 2000)\n",
      "overall test size\n",
      "(200, 22, 2000)\n",
      "2000\n",
      "(200,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 0, 1, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0, 2, 2, 2, 1, 1, 2,\n",
       "       0, 2, 0, 1, 2, 0, 1, 2, 2, 0, 2, 2, 2, 0, 1, 0, 2, 1, 0, 2, 0, 2,\n",
       "       1, 2, 2, 0, 1, 0, 0, 1, 0, 0, 2, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 2, 0, 1, 2, 1, 2, 1, 0, 0, 0, 1, 1, 2, 1, 1, 1, 0, 1, 2,\n",
       "       0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 1, 1, 0, 2, 1, 1, 2, 1, 1, 0, 1, 1,\n",
       "       0, 1, 2, 1, 2, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 1, 0, 1, 2,\n",
       "       1, 1, 1, 2, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 0, 1, 2, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 2, 1, 0, 1, 1, 0, 2, 0, 2, 0, 0, 1, 1, 0, 2, 0, 1, 2,\n",
       "       0, 1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pilotname='S2'\n",
    "savebase0='D:\\\\leaderboardData\\\\leaderboardMI\\\\'\n",
    "savebase = savebase0+pilotname+'\\\\'+'testing\\\\'\n",
    "\n",
    "# read crop data\n",
    "ch_names =['Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', \n",
    "           'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', \n",
    "           'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'C4', 'T8',\n",
    "           'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'AF7', 'AF3', \n",
    "           'AFz', 'F1', 'F5', 'FT7', 'FC3', 'FCz', 'C1', 'C5', \n",
    "           'TP7', 'CP3', 'P1', 'P5', 'PO7', 'PO3', 'POz', 'PO4', \n",
    "           'PO8', 'P6', 'P2', 'CPz', 'CP4', 'TP8', 'C6', 'C2',\n",
    "           'FC4', 'FT8', 'F6', 'F2', 'AF4', 'AF8']\n",
    "#here we used the ones arround motor cortex\n",
    "good_indices=[7,8,11,12,13,14,19,22,23,24,28]+[39,40,43,44,45,51,52,53,54,57,58]\n",
    "good_indices[:] = [x - 1 for x in good_indices]\n",
    "\n",
    "for i in range(5,15):\n",
    "    with open (savebase+\"race\"+str(i+1)+\"_padsData.npy\", 'rb') as fp:\n",
    "        Xt = pickle.load(fp)\n",
    "    if i==5:\n",
    "        X0 = Xt\n",
    "    else:\n",
    "        X0 = np.concatenate((X0,Xt))\n",
    "    print('run',i+1)\n",
    "    print(X0.shape)   \n",
    "    \n",
    "X_test = X0[:,good_indices,:]\n",
    "\n",
    "print('overall test size')\n",
    "print(X_test.shape)\n",
    "test_set = TestObject(X_test)\n",
    "\n",
    "set_random_seeds(seed=42, cuda=cuda)\n",
    "input_time_length = X_test.shape[2]\n",
    "print(input_time_length)\n",
    "in_chans=X_test.shape[1]\n",
    "labelsize=3\n",
    "model = util.shallow_net.EEGShallowClassifier(in_chans, labelsize, input_time_length, return_feature=False)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "checkpoint = torch.load('D:\\\\motor_imagery\\\\MImodelinLeaderboard\\\\'+'cnn_model_MI_'+pilotname+'.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "average_acc=[]\n",
    "average_loss=[]\n",
    "setname='testset'\n",
    "dataset=test_set\n",
    "\n",
    "i_trials_in_batch = get_balanced_batches(len(dataset.X), rng, shuffle=False,\n",
    "                                    batch_size=30)\n",
    "outputs=None\n",
    "for i_trials in i_trials_in_batch:\n",
    "    # Have to add empty fourth dimension to X\n",
    "#             print(i_trials)\n",
    "    batch_X = dataset.X[i_trials][:,:,:,None]\n",
    "#     batch_y = dataset.y[i_trials]\n",
    "    net_in = np_to_var(batch_X)\n",
    "    if cuda:\n",
    "        net_in = net_in.cuda()\n",
    "    toutputs = model(net_in)\n",
    "    if outputs is None:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=temp.detach().numpy()\n",
    "    else:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=np.concatenate((outputs,temp.detach().numpy()))\n",
    "predicted_labels = np.argmax((outputs), axis=1)\n",
    "print(predicted_labels.shape)\n",
    "MI_s2 = predicted_labels\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall test size\n",
      "(200, 32, 800)\n",
      "800\n",
      "(200,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 0, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 0, 2, 1, 0, 2, 2,\n",
       "       2, 2, 0, 2, 1, 1, 2, 2, 2, 2, 1, 0, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2,\n",
       "       1, 2, 2, 2, 1, 0, 2, 2, 1, 2, 1, 2, 0, 1, 1, 2, 2, 2, 1, 2, 2, 2,\n",
       "       1, 2, 1, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2,\n",
       "       0, 0, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 0, 1, 2,\n",
       "       1, 1, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 1, 0, 2, 1, 2, 1, 2, 2, 2, 1,\n",
       "       1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 0, 2, 1, 0,\n",
       "       1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 0, 2, 2, 1, 1, 0, 2, 0, 0, 2,\n",
       "       1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pilotname='3'\n",
    "savebase0='D:\\\\leaderboardData\\\\leaderboardMI\\\\'\n",
    "savebase = savebase0+'S'+pilotname+'\\\\testing\\\\'\n",
    "\n",
    "# read crop data\n",
    "ch_names =['Fp1', 'Fp2', 'F3', \n",
    "            'Fz', 'F4', 'FC5', 'FC1', 'FC2','FC6', 'C5', 'C3',\n",
    "           'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1',\n",
    "           'CPz', 'CP2', 'CP4', 'CP6', 'P7', 'P5', 'P3', 'P1', 'Pz', \n",
    "           'P2', 'P4', 'P6', 'P8']\n",
    "\n",
    "\n",
    "with open (savebase+\"testing_s\"+pilotname+\"X.npy\", 'rb') as fp:\n",
    "        X_test = pickle.load(fp)\n",
    "\n",
    "print('overall test size')\n",
    "print(X_test.shape)\n",
    "test_set = TestObject(X_test)\n",
    "\n",
    "set_random_seeds(seed=42, cuda=cuda)\n",
    "input_time_length = X_test.shape[2]\n",
    "print(input_time_length)\n",
    "in_chans=X_test.shape[1]\n",
    "labelsize=3\n",
    "model = util.shallow_net.EEGShallowClassifier(in_chans, labelsize, input_time_length, return_feature=False)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "checkpoint = torch.load('D:\\\\motor_imagery\\\\MImodelinLeaderboard\\\\'+'cnn_model_MI_'+pilotname+'.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "average_acc=[]\n",
    "average_loss=[]\n",
    "setname='testset'\n",
    "dataset=test_set\n",
    "\n",
    "i_trials_in_batch = get_balanced_batches(len(dataset.X), rng, shuffle=False,\n",
    "                                    batch_size=30)\n",
    "outputs=None\n",
    "for i_trials in i_trials_in_batch:\n",
    "    # Have to add empty fourth dimension to X\n",
    "#             print(i_trials)\n",
    "    batch_X = dataset.X[i_trials][:,:,:,None]\n",
    "#     batch_y = dataset.y[i_trials]\n",
    "    net_in = np_to_var(batch_X)\n",
    "    if cuda:\n",
    "        net_in = net_in.cuda()\n",
    "    toutputs = model(net_in)\n",
    "    if outputs is None:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=temp.detach().numpy()\n",
    "    else:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=np.concatenate((outputs,temp.detach().numpy()))\n",
    "predicted_labels = np.argmax((outputs), axis=1)\n",
    "print(predicted_labels.shape)\n",
    "MI_s3 = predicted_labels\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall test size\n",
      "(200, 32, 800)\n",
      "800\n",
      "(200,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 2, 2, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 2, 1, 2, 0, 1, 2, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 2, 0, 0, 2, 2, 0, 1, 0, 0, 1,\n",
       "       0, 2, 1, 1, 0, 1, 1, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 1, 1, 0, 2,\n",
       "       0, 2, 1, 0, 0, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 0, 2, 2,\n",
       "       2, 0, 2, 2, 1, 1, 0, 2, 2, 1, 0, 2, 2, 0, 1, 2, 2, 1, 0, 0, 1, 0,\n",
       "       2, 1, 2, 1, 1, 0, 0, 1, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 0,\n",
       "       2, 2, 0, 1, 2, 2, 0, 1, 2, 2, 2, 0, 0, 1, 0, 2, 1, 1, 2, 2, 0, 1,\n",
       "       0, 2, 0, 0, 2, 0, 2, 1, 2, 2, 1, 0, 2, 1, 2, 1, 0, 2, 0, 0, 2, 2,\n",
       "       0, 0, 2, 0, 0, 0, 1, 0, 2, 0, 2, 1, 2, 2, 2, 2, 0, 2, 0, 0, 2, 1,\n",
       "       2, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pilotname='4'\n",
    "savebase0='D:\\\\leaderboardData\\\\leaderboardMI\\\\'\n",
    "savebase = savebase0+'S'+pilotname+'\\\\testing\\\\'\n",
    "\n",
    "# read crop data\n",
    "ch_names =['Fp1', 'Fp2', 'F3', \n",
    "            'Fz', 'F4', 'FC5', 'FC1', 'FC2','FC6', 'C5', 'C3',\n",
    "           'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1',\n",
    "           'CPz', 'CP2', 'CP4', 'CP6', 'P7', 'P5', 'P3', 'P1', 'Pz', \n",
    "           'P2', 'P4', 'P6', 'P8']\n",
    "\n",
    "\n",
    "with open (savebase+\"testing_s\"+pilotname+\"X.npy\", 'rb') as fp:\n",
    "        X_test = pickle.load(fp)\n",
    "\n",
    "print('overall test size')\n",
    "print(X_test.shape)\n",
    "test_set = TestObject(X_test)\n",
    "\n",
    "set_random_seeds(seed=42, cuda=cuda)\n",
    "input_time_length = X_test.shape[2]\n",
    "print(input_time_length)\n",
    "in_chans=X_test.shape[1]\n",
    "labelsize=3\n",
    "model = util.shallow_net.EEGShallowClassifier(in_chans, labelsize, input_time_length, return_feature=False)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "checkpoint = torch.load('D:\\\\motor_imagery\\\\MImodelinLeaderboard\\\\'+'cnn_model_MI_'+pilotname+'.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "average_acc=[]\n",
    "average_loss=[]\n",
    "setname='testset'\n",
    "dataset=test_set\n",
    "\n",
    "i_trials_in_batch = get_balanced_batches(len(dataset.X), rng, shuffle=False,\n",
    "                                    batch_size=30)\n",
    "outputs=None\n",
    "for i_trials in i_trials_in_batch:\n",
    "    # Have to add empty fourth dimension to X\n",
    "#             print(i_trials)\n",
    "    batch_X = dataset.X[i_trials][:,:,:,None]\n",
    "#     batch_y = dataset.y[i_trials]\n",
    "    net_in = np_to_var(batch_X)\n",
    "    if cuda:\n",
    "        net_in = net_in.cuda()\n",
    "    toutputs = model(net_in)\n",
    "    if outputs is None:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=temp.detach().numpy()\n",
    "    else:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=np.concatenate((outputs,temp.detach().numpy()))\n",
    "predicted_labels = np.argmax((outputs), axis=1)\n",
    "print(predicted_labels.shape)\n",
    "MI_s4 = predicted_labels\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall test size\n",
      "(200, 32, 800)\n",
      "800\n",
      "(200,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 0, 2,\n",
       "       2, 2, 2, 2, 0, 0, 0, 2, 0, 1, 0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 1,\n",
       "       2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 0, 1, 2, 0,\n",
       "       1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 0, 2, 1, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 1, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 1, 2, 0, 0, 1, 1, 2,\n",
       "       2, 2, 2, 2, 1, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 1,\n",
       "       2, 2], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pilotname='5'\n",
    "savebase0='D:\\\\leaderboardData\\\\leaderboardMI\\\\'\n",
    "savebase = savebase0+'S'+pilotname+'\\\\testing\\\\'\n",
    "\n",
    "# read crop data\n",
    "ch_names =['Fp1', 'Fp2', 'F3', \n",
    "            'Fz', 'F4', 'FC5', 'FC1', 'FC2','FC6', 'C5', 'C3',\n",
    "           'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1',\n",
    "           'CPz', 'CP2', 'CP4', 'CP6', 'P7', 'P5', 'P3', 'P1', 'Pz', \n",
    "           'P2', 'P4', 'P6', 'P8']\n",
    "\n",
    "\n",
    "with open (savebase+\"testing_s\"+pilotname+\"X.npy\", 'rb') as fp:\n",
    "        X_test = pickle.load(fp)\n",
    "\n",
    "print('overall test size')\n",
    "print(X_test.shape)\n",
    "test_set = TestObject(X_test)\n",
    "\n",
    "set_random_seeds(seed=42, cuda=cuda)\n",
    "input_time_length = X_test.shape[2]\n",
    "print(input_time_length)\n",
    "in_chans=X_test.shape[1]\n",
    "labelsize=3\n",
    "model = util.shallow_net.EEGShallowClassifier(in_chans, labelsize, input_time_length, return_feature=False)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "checkpoint = torch.load('D:\\\\motor_imagery\\\\MImodelinLeaderboard\\\\'+'cnn_model_MI_'+pilotname+'.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "average_acc=[]\n",
    "average_loss=[]\n",
    "setname='testset'\n",
    "dataset=test_set\n",
    "\n",
    "i_trials_in_batch = get_balanced_batches(len(dataset.X), rng, shuffle=False,\n",
    "                                    batch_size=30)\n",
    "outputs=None\n",
    "for i_trials in i_trials_in_batch:\n",
    "    # Have to add empty fourth dimension to X\n",
    "#             print(i_trials)\n",
    "    batch_X = dataset.X[i_trials][:,:,:,None]\n",
    "#     batch_y = dataset.y[i_trials]\n",
    "    net_in = np_to_var(batch_X)\n",
    "    if cuda:\n",
    "        net_in = net_in.cuda()\n",
    "    toutputs = model(net_in)\n",
    "    if outputs is None:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=temp.detach().numpy()\n",
    "    else:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=np.concatenate((outputs,temp.detach().numpy()))\n",
    "predicted_labels = np.argmax((outputs), axis=1)\n",
    "print(predicted_labels.shape)\n",
    "MI_s5 = predicted_labels\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These will be the predicitons to save in a txt file. Format for text saving will be released in next update of this tutorial together with the release of leaderboard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25748,)\n",
      "(200,)\n",
      "(200,)\n",
      "(200,)\n",
      "(200,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "print(sleep_label.shape)\n",
    "print(MI_s1.shape)\n",
    "print(MI_s2.shape)\n",
    "print(MI_s3.shape)\n",
    "print(MI_s4.shape)\n",
    "print(MI_s5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 2 2 1 1 2 2 2 0 0 1 1 5 0 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(sleep_label[:20])\n",
    "#label from 0 - 5\n",
    "np.savetxt(\"util/pred_sleep_label.txt\",sleep_label,delimiter=',',fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "MI_label = MI_s1\n",
    "MI_label = np.concatenate((MI_label,MI_s2))\n",
    "MI_label = np.concatenate((MI_label,MI_s3))\n",
    "MI_label = np.concatenate((MI_label,MI_s4))\n",
    "MI_label = np.concatenate((MI_label,MI_s5))\n",
    "print(MI_label.shape)\n",
    "MI_label = MI_label.astype(int)\n",
    "MI_label[:100]\n",
    "#lable 0,1,2\n",
    "np.savetxt(\"util/pred_MI_label.txt\",MI_label,delimiter=',',fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When you upload the txt label file to CodaLab, please rename the txt file as 'answer.txt' and zip it before uploading. The score is computed according to classification accuracies with weights of inverse frequency of a label.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
